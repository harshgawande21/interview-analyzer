# ğŸ¯ Interview Analyzer - AI-Powered Interview Assessment

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/Flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15+-orange.svg)](https://tensorflow.org)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A comprehensive AI-powered interview analysis system that combines **real-time emotion detection** with **automated speech transcription** to revolutionize the interview process.

![Interview Analyzer Demo](demo/report.pdf)

## âœ¨ Key Features

### ğŸ¢ For Organizations
- **ğŸ“„ PDF Question Upload** - Extract interview questions from PDF documents
- **ğŸ“Š Real-time Analytics** - Live emotion tracking with comprehensive pie charts
- **ğŸ¯ Session Management** - Secure, unique interview sessions
- **ğŸ“ Answer Transcription** - Automatic speech-to-text conversion
- **ğŸ“ˆ Detailed Reports** - Complete emotion analysis and response data

### ğŸ‘¤ For Candidates  
- **â±ï¸ Timed Questions** - 3-minute countdown timer per question
- **ğŸ¤ Speech Recognition** - Automatic answer transcription
- **ğŸ“¹ Live Emotion Detection** - Real-time emotion analysis every 10 seconds
- **ğŸ“Š Progress Tracking** - Visual progress indicators
- **âœ¨ Professional Interface** - Modern, responsive design

### ğŸ¤– AI-Powered Analysis
- **7 Emotion Detection** - Happy, Sad, Angry, Surprise, Fear, Disgust, Neutral
- **Real-time Processing** - CNN-based emotion classification
- **Confidence Scoring** - Reliable emotion detection with thresholds
- **Timeline Analysis** - Emotion tracking throughout the interview

## ğŸš€ Quick Start

### 1. Installation
```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/interview-analyzer.git
cd interview-analyzer

# Install dependencies
pip install -r requirements.txt

# Run the application
python start.py
```

### 2. Access the Application
Open your browser and navigate to: **http://localhost:5000**

### 3. Usage
1. **Organizations**: Upload PDF questions â†’ Start interview session â†’ Share link
2. **Candidates**: Use interview link â†’ Allow camera/mic â†’ Answer questions

## ğŸ“‹ Requirements

- **Python 3.7+**
- **Webcam and Microphone**
- **Modern Browser** (Chrome recommended for speech recognition)
- **Model Files**: `emotion_model.hdf5` and `haarcascade_frontalface_default.xml`

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Organization  â”‚    â”‚   Flask Server   â”‚    â”‚   Candidate     â”‚
â”‚   Dashboard     â”‚â—„â”€â”€â–ºâ”‚  + SocketIO      â”‚â—„â”€â”€â–ºâ”‚   Interface     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  AI Emotion      â”‚
                    â”‚  Detection       â”‚
                    â”‚  (CNN + OpenCV)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Technology Stack

- **Backend**: Flask, SocketIO, TensorFlow, OpenCV
- **Frontend**: Bootstrap 5, Chart.js, WebRTC
- **AI/ML**: Keras CNN, Haar Cascades, Real-time Processing
- **Communication**: WebSocket, REST API

## ğŸ“ Project Structure

```
interview-analyzer/
â”œâ”€â”€ ğŸ“„ app.py                    # Main Flask application
â”œâ”€â”€ ğŸ“„ config.py                 # Configuration management  
â”œâ”€â”€ ğŸ“„ start.py                  # Simple startup script
â”œâ”€â”€ ğŸ“ templates/                # HTML templates
â”‚   â”œâ”€â”€ base.html               # Base template with styling
â”‚   â”œâ”€â”€ index.html              # Landing page
â”‚   â”œâ”€â”€ organization.html       # Organization dashboard
â”‚   â””â”€â”€ candidate.html          # Candidate interface
â”œâ”€â”€ ğŸ“ static/css/              # Custom styling
â”œâ”€â”€ ğŸ“ models/                  # AI model files
â”œâ”€â”€ ğŸ“ utils/                   # Utility functions
â””â”€â”€ ğŸ“ demo/                    # Demo files
```

## ğŸ¨ Screenshots

### Landing Page
Modern glass morphism design with role selection

### Organization Dashboard  
PDF upload, question preview, and session management

### Candidate Interface
Real-time emotion detection with speech transcription

### Analytics Dashboard
Comprehensive emotion analysis with interactive charts

## ğŸ”§ Configuration

The application uses a flexible configuration system in `config.py`:

```python
# Interview settings
QUESTION_TIME_LIMIT = 180  # 3 minutes
EMOTION_DETECTION_INTERVAL = 10  # seconds
MAX_QUESTIONS_PER_INTERVIEW = 20

# AI settings  
EMOTION_OFFSETS = (20, 40)
DETECTION_CONFIDENCE_THRESHOLD = 0.5
```

## ğŸ§ª Testing

Run the system test to verify everything is working:

```bash
python test_emotion_detection.py
```

This will test:
- âœ… Dependencies installation
- âœ… Model loading
- âœ… Camera access
- âœ… Face detection
- âœ… Emotion prediction

## ğŸ“š Documentation

- **[User Guide](README_INTERVIEW_ANALYZER.md)** - Complete setup and usage instructions
- **[Project Overview](PROJECT_OVERVIEW.md)** - Detailed technical documentation
- **[Installation Guide](install.py)** - Automated installation helper

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ› Troubleshooting

### Common Issues

**Camera/Microphone Access Denied**
- Ensure HTTPS or localhost access
- Check browser permissions

**Speech Recognition Not Working**  
- Use Chrome or Edge browser
- Check microphone permissions

**Emotion Detection Failing**
- Ensure good lighting
- Position face clearly in camera view
- Verify model files are present

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Original emotion detection model from [oarriaga/face_classification](https://github.com/oarriaga/face_classification)
- OpenCV for computer vision capabilities
- Flask and SocketIO for real-time web communication

## ğŸ“ Support

For support, please create an issue in this repository or contact the maintainers.

---

**Built with â¤ï¸ for revolutionizing the interview process through AI-powered insights.**